"""
GPU-Optimized Main Pipeline for Face Recognition Attendance System.
Use this instead of main.py when GPU is available for 10-20x speedup.

Features:
- Batch face processing
- Single-model optimization (RetinaFace + ArcFace)
- Face Tracking (Detect once, track N frames)
- Event-based recognition (Identity stability filter)
- GPU-accelerated preprocessing
- Real-time FPS and GPU memory monitoring
"""
import os
import sys
import logging
import traceback
import time
import cv2
import numpy as np
from pathlib import Path
from sqlalchemy.orm import Session

# 0. Early GPU & Environment Setup
try:
    import site
    
    # 1. Force Legacy Keras for compatibility with DeepFace and Keras 3 issues
    os.environ["TF_USE_LEGACY_KERAS"] = "1"
    os.environ["KERAS_BACKEND"] = "tensorflow"
    
    # 2. Set CUDA Visibility
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    
    # 2. Aggressive Library Linking
    site_packages = site.getsitepackages()
    cuda_lib_paths = []
    # Prioritize venv libraries
    for sp in site_packages:
        nvidia_path = Path(sp) / "nvidia"
        if nvidia_path.exists():
            # Add all lib directories under nvidia/
            for lib_dir in nvidia_path.glob("**/lib"):
                if lib_dir.is_dir():
                    cuda_lib_paths.append(str(lib_dir))
    
    # Common system paths
    cuda_lib_paths.extend([
        "/usr/local/cuda/lib64",
        "/usr/lib/x86_64-linux-gnu",
        "/usr/lib/x86_64-linux-gnu/nvidia",
        "/usr/local/cuda/targets/x86_64-linux/lib"
    ])
    
    if cuda_lib_paths:
        unique_paths = list(dict.fromkeys(cuda_lib_paths))
        # Add side-loaded cuDNN 8 for TensorFlow
        tf_cudnn8_path = "/home/ayoub/projects/Ai-Ml/emsvia/libs/cudnn8"
        if os.path.exists(tf_cudnn8_path):
            unique_paths.insert(0, tf_cudnn8_path)
            
            # PRE-LOAD LIBRARIES to ensure they are available to TensorFlow
            import ctypes
            for lib_name in [
                "libcudnn.so.8", "libcudnn_ops_infer.so.8", "libcudnn_cnn_infer.so.8",
                "libcudnn_adv_infer.so.8"
            ]:
                try:
                    ctypes.CDLL(os.path.join(tf_cudnn8_path, lib_name), mode=ctypes.RTLD_GLOBAL)
                    sys.stdout.write(f"  üì¶ Pre-loaded {lib_name}\n")
                except Exception as le:
                    sys.stdout.write(f"  ‚ö†Ô∏è  Failed to pre-load {lib_name}: {le}\n")
            
        current_ld = os.environ.get("LD_LIBRARY_PATH", "")
        new_ld = ":".join(unique_paths)
        if current_ld:
            new_ld = f"{new_ld}:{current_ld}"
        
        os.environ["LD_LIBRARY_PATH"] = new_ld
        
        # Link for TensorFlow XLA
        for p in unique_paths:
            if "cuda_runtime" in p:
                os.environ["XLA_FLAGS"] = f"--xla_gpu_cuda_data_dir={p.split('/lib')[0]}"
                break

    import torch
    if torch.cuda.is_available():
        torch.cuda.init()
        sys.stdout.write(f"üöÄ PyTorch CUDA Initialized: {torch.cuda.get_device_name(0)}\n")
    else:
        sys.stdout.write("‚ö†Ô∏è  PyTorch: CUDA NOT available.\n")

    # Important: Check TensorFlow GPU availability
    import tensorflow as tf
    try:
        # Prevent TF from taking all VRAM
        tf_gpus = tf.config.list_physical_devices('GPU')
        if tf_gpus:
            sys.stdout.write(f"‚úÖ TensorFlow GPU(s) found: {len(tf_gpus)}\n")
            for gpu in tf_gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
        else:
            sys.stdout.write("‚ùå TensorFlow: GPU NOT FOUND. Inference will be slow (CPU).\n")
    except Exception as tfe:
        sys.stdout.write(f"‚ö†Ô∏è  TensorFlow init warning: {tfe}\n")
    
    sys.stdout.flush()
except Exception as e:
    sys.stdout.write(f"‚ö†Ô∏è  Early Environment Setup warning: {e}\n")
    sys.stdout.flush()

# Set TF specific flags
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=0 --tf_xla_cpu_global_jit'

# Try to limit TF VRAM early
import tensorflow as tf
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'
# Set limit to 60% of GPU to avoid competition with Torch/OS
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        tf.config.set_logical_device_configuration(
            gpus[0],
            [tf.config.LogicalDeviceConfiguration(memory_limit=2500)] # ~2.5GB limit
        )
    except Exception:
        pass

# Add project root to sys.path
BASE_DIR = Path(__file__).resolve().parent
sys.path.append(str(BASE_DIR))

from config.settings import (
    DATABASE_URL, IDENTITY_STABILITY_THRESHOLD, MIN_BUFFER_FOR_RECOG, 
    RECOGNITION_MODELS, DEBUG_MODE, DETECTION_SKIP_FRAMES, RECOGNITION_INTERVAL_FRAMES,
    BATCH_PROCESSING, BATCH_SIZE, CLEAR_CACHE_INTERVAL, USE_GPU
)
from database.crud import AttendanceDB
from models.face_detector import FaceDetector
from models.face_recognizer import FaceRecognizer
from models.embeddings_manager import EmbeddingsManager
from models.gpu_manager import GPUModelManager
from core.camera_handler import CameraHandler
from core.attendance_manager import AttendanceManager
from core.unknown_face_handler import UnknownFaceHandler
from core.tracker import FaceTracker
from recognition.batch_recognizer import BatchRecognizer
from detection.parallel_detector import ParallelDetector
from utils.gpu_utils import GPUMemoryManager

# Configure Logging
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def main():
    """
    GPU-Optimized main entry point for real-time attendance system.
    """
    logger.info("="*60)
    logger.info("üöÄ Starting Optimized Industry-Grade Attendance System")
    logger.info("="*60)
    
    # 1. Initialize GPU Manager
    gpu_mgr = GPUModelManager()
    if not gpu_mgr.is_gpu_ready():
        logger.warning("‚ö†Ô∏è  GPU not detected! Performance will be affected.")
    else:
        logger.info(f"‚úÖ GPU Ready: {gpu_mgr.get_memory_summary()}")
    
    # 2. Initialize Database and Embeddings
    db_manager = AttendanceDB(DATABASE_URL)
    em_manager = EmbeddingsManager(db_manager)
    session = db_manager.get_session()
    em_manager.load_embeddings(session)
    students = db_manager.get_all_students(session)
    student_names = {s.id: f"{s.first_name} {s.last_name}" for s in students}
    session.close()
    logger.info(f"üë®‚Äçüéì Loaded {len(student_names)} students from database")
    
    # 3. Load Models
    logger.info("üì¶ Loading models...")
    detector = FaceDetector()
    recognizer = FaceRecognizer()
    
    # Parallel detection handler
    if BATCH_PROCESSING and gpu_mgr.is_gpu_ready():
        parallel_detector = ParallelDetector(detector)
    else:
        parallel_detector = None
    
    # 4. Core Handlers
    camera = CameraHandler(source=0).start()
    attend_mgr = AttendanceManager(db_manager)
    unknown_mgr = UnknownFaceHandler(db_manager)
    tracker = FaceTracker()
    
    # 5. Processing Settings
    detection_skip = DETECTION_SKIP_FRAMES
    recognition_interval = RECOGNITION_INTERVAL_FRAMES
    logger.info(f"‚öôÔ∏è  Detection Skip: {detection_skip} frames")
    logger.info(f"‚öôÔ∏è  Recognition Interval: {recognition_interval} frames")
    
    frame_idx = 0
    fps_history = []
    last_gpu_log_time = time.time()
    
    logger.info("üé¨ Processing loop started. Press 'q' to quit.")
    
    try:
        while True:
            loop_start = time.time()
            ret, frame = camera.read()
            if not ret or frame is None: continue
            
            frame_idx += 1
            display_frame = camera.preprocess_frame(frame)
            session = db_manager.get_session()
            
            try:
                # 1. DETECTION & TRACKING
                t_det_start = time.time()
                if frame_idx % detection_skip == 0 or frame_idx == 1:
                    if parallel_detector and gpu_mgr.is_gpu_ready():
                        faces = parallel_detector.detect_ensemble(frame, use_tiling=False)
                    else:
                        faces = detector.detect_faces(frame)
                    tracked_faces = tracker.update(faces)
                else:
                    tracked_faces = tracker.update([])
                t_det = (time.time() - t_det_start) * 1000
                
                active_track_ids = {f['track_id'] for f in tracked_faces}
                
                # 2. PROCESS TRACKS
                t_rec = 0
                for face in tracked_faces:
                    x, y, w, h = face['box']
                    tid = face['track_id']
                    track_data = tracker.tracks.get(tid)
                    if not track_data: continue
                    
                    track_data['frame_count'] += 1
                    
                    # UI Mirroring logic
                    img_w_disp = display_frame.shape[1]
                    x_disp = img_w_disp - (x + w)
                    color = (255, 128, 0) # Orange for tracking
                    label = f"Scanning... (T:{tid})"
                    
                    # 3. RECOGNITION (Event-based)
                    stable_id = track_data['current_identity']
                    needs_recognition = False
                    
                    if stable_id is None:
                        if track_data['frame_count'] % 5 == 0: needs_recognition = True
                    else:
                        if track_data['frame_count'] % recognition_interval == 0: needs_recognition = True

                    if needs_recognition:
                        t_rec_start = time.time()
                        face_crop = detector.extract_face(frame, [x, y, w, h])
                        if face_crop is not None and detector.check_image_quality(face_crop)['passed']:
                            current_embeddings = recognizer.generate_embeddings(face_crop)
                            if current_embeddings:
                                all_known = em_manager.get_all_embeddings()
                                match_result = recognizer.find_best_match(current_embeddings, all_known)
                                track_data['last_match'] = match_result
                                
                                new_id = match_result["student_id"] if match_result["match_found"] else None
                                
                                if new_id:
                                    if new_id == track_data['current_identity']:
                                        track_data['identity_stability_counter'] = 0
                                    else:
                                        track_data['identity_stability_counter'] += 1
                                        if track_data['identity_stability_counter'] >= IDENTITY_STABILITY_THRESHOLD:
                                            track_data['current_identity'] = new_id
                                            track_data['identity_stability_counter'] = 0
                                            logger.info(f"‚ú® Track {tid} identified as: {student_names.get(new_id, new_id)}")
                                else:
                                    if track_data['frame_count'] % 100 == 0:
                                        unknown_mgr.handle_unknown_face(session, face_crop, confidence=0.0)
                        t_rec += (time.time() - t_rec_start) * 1000

                    # 4. MARK ATTENDANCE & UI
                    stable_id = track_data['current_identity']
                    if stable_id:
                        name = student_names.get(stable_id, f"ID: {stable_id}")
                        label = f"{name}"
                        color = (0, 255, 0) # Green
                        attend_mgr.process_recognition(session, stable_id, track_id=tid, confidence=1.0)
                    elif track_data.get('last_match') and not track_data['last_match']['match_found']:
                        label = f"Unknown (T:{tid})"
                        color = (0, 0, 255) # Red
                    
                    cv2.rectangle(display_frame, (x_disp, y), (x_disp + w, y + h), color, 2)
                    cv2.putText(display_frame, label, (x_disp, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                
                attend_mgr.clean_stale_tracks(active_track_ids)
                
            finally:
                session.close()
            
            # FPS Calculation
            fps = camera.get_fps()
            fps_history.append(fps)
            if len(fps_history) > 30: fps_history.pop(0)
            avg_fps = sum(fps_history) / len(fps_history)
            
            # Display Overlays
            cv2.putText(display_frame, f"FPS: {avg_fps:.1f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(display_frame, f"Det: {t_det:.0f}ms | Rec: {t_rec:.0f}ms", (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            if gpu_mgr.is_gpu_ready():
                cv2.putText(display_frame, gpu_mgr.get_memory_summary(), (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
            
            cv2.imshow("Industry-Grade Attendance System", display_frame)
            
            if gpu_mgr.is_gpu_ready():
                gpu_mgr.auto_clear_cache()
                if time.time() - last_gpu_log_time > 30:
                    logger.info(f"üìä Stats - FPS: {avg_fps:.1f} | Det: {t_det:.1f}ms | Rec: {t_rec:.1f}ms | GPU: {gpu_mgr.get_memory_summary()}")
                    last_gpu_log_time = time.time()
            
            if cv2.waitKey(1) & 0xFF == ord('q'): break
            
    except Exception as e:
        logger.error(f"‚ùå Error: {e}")
        logger.error(traceback.format_exc())
    finally:
        camera.stop()
        cv2.destroyAllWindows()
        logger.info("üßπ Cleanup complete.")

if __name__ == "__main__":
    main()
